\section{Estado del Arte}
En esta sección describiremos en qué se diferencian las aplicaciones descentralizadas de aquellas centralizadas, cuáles son las ventajas (y desventajas) del modelo de aplicación distribuido, y qué tecnologías existen actualmente para asistir en la creación de dichas aplicaciones.

\subsection{Introducción a arquitecturas de red}
La comunicación entre distintas computadoras requiere una coordinación efectiva entre todas las partes involucradas, el uso de protocolos que estandaricen la forma en que se transmite la información, y una infraestructura que permita enviar cada \textit{bit} desde el origen hasta su destino. Para ofrecer servicios a través de Internet, es necesario diseñar una red bien estructurada que cumpla con estos requisitos. En este contexto, existen dos arquitecturas principales que permiten alcanzar dicho objetivo.

\subsubsection*{Cliente-Servidor}
El modelo Cliente-Servidor es ampliamente utilizado en la mayoría de las aplicaciones disponibles en Internet. Consiste en un nodo central, el servidor, responsable de gestionar las interacciones entre los usuarios, así como las comunicaciones directas entre cada usuario y el propio servidor. En este esquema, los demás nodos actúan como clientes, solicitando servicios o recursos que el servidor proporciona.

Este modelo se clasifica como una arquitectura centralizada, ya que la subred depende directamente del servidor. En caso de que este nodo central falle, los clientes pierden la capacidad de comunicarse entre sí o acceder a los servicios, lo que representa un punto único de fallo.

Entre los servicios más comunes que adoptan esta arquitectura se encuentran la World Wide Web (HTTP/HTTPS), el correo electrónico (SMTP, IMAP) y el sistema de DNS, entre otros.

\subsubsection*{Peer-to-Peer}
El modelo \textit{\textbf{peer-to-peer}}(P2P) consiste en una red \textbf{descentralizada} compuesta de diferentes nodos capaces de comunicarse sin necesidad de un nodo central, por lo que se puede considerar que cada nodo cumple la función tanto de servidor como de cliente.

\paragraph{BitTorrent} El servicio más utilizado que implementa este modelo es la red de BitTorrent \cite{bittorrent}, que implementa el protocolo del mismo nombre para compartir archivos entre pares. Esta red logra que el mismo nodo que descarga un contenido de la red sea a la vez el servidor para otro nodo que quiera acceder a ese contenido. 

\subsection{Diferencias y ventajas de cada arquitectura}
Ambos modelos tienen ventajas y desventajas, y por lo tanto distintos casos de uso. El modelo cliente-servidor actualmente es la arquitectura más utilizada.

\paragraph{Resiliencia}
En el modelo cliente-servidor, la disponibilidad de la red depende críticamente del servidor central. Si este falla o queda fuera de servicio, los clientes no pueden acceder a los recursos, lo que puede interrumpir por completo el funcionamiento del sistema. Para mitigar esta vulnerabilidad, se han implementado soluciones como la replicación de servidores en distintas ubicaciones geográficas, el balanceo de carga \cite{bourke2001server} y el uso de fuentes de energía alternativas, todo con el fin de mejorar la tolerancia a fallos y garantizar una mayor disponibilidad.

En contraste, una red P2P se basa en una arquitectura descentralizada en la que los nodos actúan simultáneamente como clientes y servidores. Esta estructura distribuye la responsabilidad entre múltiples participantes, lo que permite que la red siga operando incluso si varios nodos se desconectan. Cuando los pares están lo suficientemente dispersos geográficamente y hay una cantidad adecuada de ellos, el sistema puede mantener su funcionalidad frente a fallos locales, cortes de energía o incluso desastres naturales. Esta resiliencia inherente hace que el modelo P2P sea especialmente atractivo para servicios que requieren alta disponibilidad o continuidad operativa en condiciones adversas.

No obstante, la robustez de una red P2P depende del nivel de redundancia de los datos distribuidos. Si la red cuenta con pocos nodos o si los datos no están replicados entre varios pares, la desconexión de un nodo puede provocar la pérdida temporal de parte del contenido. En estos casos, aunque la red permanezca activa, su funcionalidad puede verse comprometida. Por tanto, garantizar la resiliencia en un entorno P2P también implica diseñar mecanismos eficientes de replicación y distribución de la información.

\paragraph{Escalabilidad}
Una de las principales ventajas de las redes \textit{peer-to-peer} (P2P) es su escalabilidad. A medida que se suman más nodos a la red, también aumentan los recursos disponibles —como capacidad de procesamiento, almacenamiento y ancho de banda— lo que permite distribuir la carga de forma más eficiente. En una red P2P bien diseñada, cada nuevo participante no solo consume recursos, sino que también contribuye al sistema, favoreciendo un crecimiento orgánico y sostenible.

En cambio, en el modelo cliente-servidor, escalar implica aumentar la capacidad del servidor o incorporar servidores adicionales para atender la creciente demanda. Esto conlleva costos significativos en términos de infraestructura, mantenimiento y administración. En aplicaciones de gran escala, como redes sociales o servicios de \textit{streaming}, es común la implementación de clústeres de servidores y redes de de CDN (\textit{Content Delivery Network}) para evitar cuellos de botella y garantizar el rendimiento, lo cual aumenta la complejidad técnica y económica del sistema.

\paragraph{Control del contenido}
En una arquitectura cliente-servidor, el servidor central debe gestionar múltiples conexiones simultáneas, lo cual requiere una infraestructura robusta que la mayoría de los usuarios no está en condiciones de mantener. Por esta razón, muchas aplicaciones recurren al alojamiento en plataformas de computación en la nube, como AWS, Azure o Google Cloud. Si bien estos servicios ofrecen alta disponibilidad y escalabilidad, también centralizan el control del contenido. Esto implica que las plataformas de \textit{hosting} tienen la capacidad de modificar, censurar o eliminar aplicaciones y servicios, ya sea por decisión propia, por presión de gobiernos, o en cumplimiento de políticas internas.

En contraste, una red \textit{peer-to-peer} (P2P) distribuye el contenido entre los propios usuarios, quienes actúan como anfitriones del sistema. Esta descentralización hace que la moderación de contenido sea mucho más difícil, ya que no existe un único punto de control. Esta característica resulta valiosa en contextos donde el acceso a la información está restringido por censura gubernamental o limitaciones regulatorias. Sin embargo, también plantea desafíos éticos y legales, ya que dificulta el control sobre la difusión de contenidos ilícitos o perjudiciales. Así, el modelo P2P ofrece mayor libertad, pero también exige nuevas formas de regulación y responsabilidad colectiva.

\paragraph{Seguridad}
La seguridad en aplicaciones basadas en el modelo cliente-servidor ha sido ampliamente estudiada debido a su larga trayectoria y adopción masiva. La centralización permite al administrador del sistema aplicar políticas de seguridad de forma coherente, como el bloqueo de conexiones sospechosas, la autenticación de usuarios y la eliminación de contenido malicioso, todo sin requerir intervención directa del usuario final.

En cambio, las redes P2P presentan desafíos distintos. Al no existir un punto de control central, la responsabilidad de establecer conexiones seguras recae en cada nodo participante. La ausencia de una autoridad central puede dificultar la detección y mitigación de comportamientos maliciosos dentro de la red.

Sin embargo, independientemente del modelo arquitectónico adoptado, la seguridad general de una aplicación dependerá en gran medida de su propio diseño: el uso adecuado de cifrado, autenticación, y la gestión de vulnerabilidades son factores determinantes para garantizar la protección de los datos y de los usuarios.

\paragraph{Persistencia}
En redes descentralizadas, la persistencia depende del comportamiento de los nodos y de las características específicas de la aplicación. En sistemas como BitTorrent, cada nodo que descarga un archivo puede continuar compartiéndolo con otros participantes, lo que genera una forma de redundancia dinámica: a medida que más usuarios descargan un archivo, aumentan las copias disponibles en la red. Sin embargo, si un archivo no es ampliamente compartido, puede volverse inaccesible cuando los pocos nodos que lo contienen se desconectan. En este sentido, la persistencia en redes \textit{peer-to-peer} no está garantizada por diseño, sino que depende del nivel de replicación voluntaria entre los pares.

\paragraph{Latencia}
Dada una conexión a Internet promedio, las velocidades manejadas por las aplicaciones cliente-servidor suelen ser aceptables. Sin embargo, en zonas en donde la conexión es escasa, o en casos en donde el servidor está lejos del cliente, la velocidad de transferencia de la aplicación puede verse afectada. Además, no es infrecuente encontrar cortes en videollamadas, videojuegos, y demás aplicaciones de tiempo real que siguen esta arquitectura. Como en la mayoría de defectos del modelo cliente-servidor, se puede solucionar agregando múltiples instancias del servidor. Por ejemplo, es común almacenar  películas, videos y demás contenido de aplicaciones de \textit{streaming} en distintos servidores de CDN. Estas redes minimizan la distancia entre el usuario y el servidor, agilizando así la transferencia del contenido.

A pesar de los avances en la optimización del modelo cliente-servidor, las redes descentralizadas, cuando son eficientes y están bien pobladas, suelen ofrecer incluso mejores resultados. Esto se debe a que la fuente de un contenido puede estar presente en múltiples nodos, lo que aumenta la probabilidad de que un nodo cercano tenga el contenido solicitado. La velocidad de transferencia que puede proporcionar un vecino con el contenido que requerimos generalmente superará la ofrecida por un servidor.

\paragraph{Costos}
Una de las ventajas del modelo \textit{peer-to-peer} (P2P) es su bajo costo operativo. Dado que los propios usuarios de la red aportan recursos como almacenamiento, procesamiento y ancho de banda, no es necesario mantener una infraestructura centralizada para alojar la aplicación. Esto reduce considerablemente los gastos asociados a la implementación y mantenimiento del sistema.

En contraste, el modelo cliente-servidor requiere disponer de un servidor dedicado o contratar servicios de alojamiento web, cuyos costos suelen incrementarse a medida que la aplicación escala y atrae más usuarios. Estos gastos incluyen no solo el \textit{hardware} o el servicio de \textit{hosting}, sino también aspectos como soporte técnico, ancho de banda adicional y medidas de seguridad. Por ello, las arquitecturas descentralizadas pueden representar una alternativa económicamente viable, especialmente en contextos donde los recursos financieros son limitados o se busca una solución escalable con bajo mantenimiento central.

\subsection{Ambientes y herramientas}
Existen varios ecosistemas que apuntan a proveer un marco con el cuál desarrollar una aplicación descentralizada. A su vez, cada uno de ellos cuenta con herramientas especializadas para los diferentes tipos de aplicaciones.

\subsubsection{IPFS}

\textbf{IPFS} (\textit{InterPlanetary File System}) es un conjunto modular de protocolos diseñado para la organización y transferencia de datos en una red \textit{peer-to-peer}, basado en el principio de \textbf{direccionamiento por contenido}, es decir, la recuperación de archivos en función de su contenido y no de su ubicación o identificador arbitrario \cite{ipfs}. Su principal propósito es facilitar la publicación de datos como archivos, directorios y sitios web de forma descentralizada, conformando así un sistema de archivos global, distribuido y descentralizado.

Este enfoque representa una alternativa al modelo tradicional de la web, que se basa en el direccionamiento por ubicación (\textit{location-based addressing}), como ocurre con HTTP. Dicho modelo impone limitaciones estructurales que son contrarias a los principios de descentralización y autonomía que caracterizan a las aplicaciones comunitarias y distribuidas.

IPFS, en cambio, propone una red abierta, participativa y sin control centralizado, donde cualquier usuario puede contribuir y operar como nodo. Esta descentralización brinda la posibilidad de evitar la dependencia de servicios de terceros para el despliegue de aplicaciones —lo cual puede resultar costoso—, al permitir que los propios usuarios colaboren activamente con recursos de sus dispositivos para sostener el funcionamiento de la red.

Además, gracias al direccionamiento por contenido, cada archivo en IPFS cuenta con un identificador único —llamado \textit{Content Identifier}, o CID—, lo que permite un acceso persistente y distribuido desde múltiples ubicaciones. Esta característica mejora la disponibilidad del contenido y fortalece la resistencia frente a intentos de censura o interrupciones del servicio.

En este contexto, IPFS constituye una base tecnológica especialmente adecuada para el desarrollo de aplicaciones descentralizadas. A continuación, se presentan algunas de las herramientas más relevantes que conforman su ecosistema.

\paragraph{libp2p}
Colección de protocolos y utilidades para facilitar la implementación de una red  \textit{peer-to-peer} \cite{libp2p}. Entre sus herramientas, se encuentran diferentes mecanismos de seguridad, de transporte, y para descubrimiento de pares. Se creó con IPFS en mente, pero luego se expandió a un conjunto de protocolos independiente, el cual es utilizado por Ethereum actualmente. Los protocolos de interés para este proyecto son:

\subparagraph{Protocolos de transporte} 
Son los encargados de la comunicación entre nodos, de manera similar a la capa de transporte presente en toda red convencional. Se basan en tipos de transporte ya existentes, adaptados al uso  \textit{peer-to-peer}. Los protocolos principales son TCP, WebSockets y WebRTCDirect.

\subparagraph{Protocolos de descubrimiento de peers} Para encontrar un contenido en IPFS, no es necesario conocer de antemano la dirección del nodo que lo almacena. Al contrario, alcanza con conocer el hash del contenido, y la red se encarga de localizar uno o más nodos que lo tengan disponible en ese momento. El principal protocolo utilizado para esto se denomina Distributed Hash Table (DHT) \cite{dht} \cite{kadmelia}. Se trata de un registro clave-valor distribuido entre todos los nodos que soportan este protocolo, el cual contiene la información necesaria para encontrar el contenido deseado. Cada nodo mantiene una porción de esta tabla y puede realizar consultas a otros nodos para descubrir qué peer posee el contenido buscado.

\paragraph{Kubo}
La implementación principal de IPFS es Kubo, una solución hecha en Go \cite{kubo}. Tiene su propio comando en la terminal, llamado \texttt{ipfs}, y también es utilizado en los demás \textit{front-ends} de IPFS como \textit{IPFS Desktop}, la aplicación de escritorio de IPFS. Es la más madura y desarrollada de las dos implementaciones de IPFS, y cuenta con más funcionalidades.

\paragraph{IPFS Cluster} 
Es una herramienta diseñada para coordinar múltiples nodos de IPFS con el fin de facilitar la replicación y sincronización de contenidos en la red \cite{ipfs-cluster}. Su función principal es garantizar la alta disponibilidad y persistencia de los datos distribuidos, permitiendo que varios nodos colaboren para mantener y distribuir los archivos de manera eficiente y resiliente.

\subparagraph{Clústeres colaborativos} 

Se trata de configuraciones de clústeres que permiten la participación de usuarios mediante sus propios nodos para incrementar la disponibilidad y redundancia del contenido replicado \cite{collaborative-clusters}. Esta característica resulta particularmente adecuada para aplicaciones comunitarias, dado que posibilita la colaboración abierta sin comprometer la seguridad ni el control sobre los datos almacenados.

\paragraph{OrbitDB}
Es una base de datos descentralizada y \textit{peer-to-peer} construida sobre \textbf{IPFS} para el almacenamiento distribuido de datos, y que utiliza \textbf{libp2p} para la sincronización y comunicación entre nodos \cite{orbitdb}. Su modelo de consistencia es eventual, lo que implica que los cambios realizados en una instancia de la base de datos no se reflejan instantáneamente en todos los nodos, sino que se propagan progresivamente a lo largo del tiempo.
OrbitDB ha sido desarrollada principalmente dentro del ecosistema JavaScript, lo cual facilita su integración en aplicaciones web y permite la ejecución de nodos directamente en el navegador.

\paragraph{Helia}
Helia es una implementación de IPFS en JavaScript que puede ejecutarse tanto en navegadores como en entornos de servidor \cite{helia}. A diferencia de Kubo, Helia ofrece un enfoque más abierto y flexible para la configuración del nodo \textit{libp2p} que utiliza internamente. Esta flexibilidad permite adaptar el nodo a diversos escenarios y necesidades específicas, aunque también implica una mayor complejidad para garantizar un funcionamiento correcto y estable.

\subsubsection{Blockchain}

Es una tecnología basada en una cadena de bloques de operaciones descentralizada.  Esta tecnología genera una base de datos compartida a la que tienen acceso sus participantes, los cuáles pueden rastrear cada transacción que hayan realizado. En la actualidad, existen diversas implementaciones de \textit{blockchains} que permiten la creación de aplicaciones descentralizadas.

\paragraph{Ethereum} Es una de las \textit{blockchains} públicas más utilizadas hoy en día \cite{wood2014ethereum}. Está compuesta de nodos distribuidos de manera descentralizada que comparten poder de cómputo sobre los cuales se desarrollan aplicaciones descentralizadas. Cuenta con una criptomoneda llamada ETH que funciona a modo de incentivo, es decir que los nodos reciben ganancias por formar parte de la red. Esto conlleva a que los usuarios de la red necesiten pagar para utilizarla a través de transacciones. Las aplicaciones en Ethereum funcionan mediante \textit{smart contracts} inmutables que son desarrollados en el lenguaje Solidity.

\paragraph{Swarm} Es un almacenamiento descentralizado que corre sobre una \textit{sidechain} de Ethereum \cite{team2021swarm}. Surgió como uno de los tres pilares de Ethereum para una web descentralizada \parencite{swarm-origin}. Funciona por \textit{content addressing} como IPFS e incluye un modelo de incentivos utilizando su propia criptomoneda llamada BZZ.

\subsubsection{Alternativas}
\paragraph{Hyphanet} Es una plataforma  \textit{peer-to-peer} para publicar y comunicar, resistente a la censura y respetuosa de la privacidad \cite{hyphanet-white-paper} \cite{hyphanet}. Originalmente conocido como Freenet y creado como un trabajo profesional de fin de carrera por Ian Clarke, Hyphanet es una plataforma de software libre que permite compartir archivos, navegar y publicar sitios de forma anónima. Es descentralizado para hacerlo menos vulnerable a ataques, y de ser usado sólo con personas de confianza lo hace difícil de detectar para agentes externos.

\paragraph{Freenet} Es una red  \textit{peer-to-peer} para servicios descentralizados, sin censura, en donde los usuarios tengan el control del contenido \cite{freenet}. Es una plataforma que transforma las computadoras de sus usuarios en plataformas distribuidas y resilientes en la que se pueden construir aplicaciones descentralizadas. Cada  \textit{peer} contribuye a un colectivo tolerante a fallas, asegurando que los servicios robustos que estén siempre disponibles.

Creado por Ian Clarke, el mismo creador de \textit{Hyphanet} \cite{hyphanet}, es una plataforma nueva que busca ser una computadora descentralizada en reemplazo de servidores centralizados. Está hecha en Rust y utiliza WebAssembly para ejecutar las aplicaciones.


\subsection{Soluciones existentes}

\subsubsection{IPFS Deploy Action}
Para desplegar un sitio web en IPFS, se puede utilizar un GitHub Action \cite{ipfs-deploy-action} desarrollado por IPFS y lanzado en Febrero de 2025. Dicha herramienta es un \textit{script} que se ejecuta con cada \textit{commit} en un repositorio de GitHub, y permite compilar el sitio web, y luego alojarlo en IPFS utilizando un servicio de \textit{pinning}, Filecoin, o bien un clúster de IPFS. Estas opciones se verán en detalle cuando se abarque la arquitectura de despliegue implementada.

Sin embargo, cuenta con una serie de desventajas al utilizar un \textit{cluster}. Por un lado, utilizando la opción de \textit{cluster} sólo puede instruir a un único nodo para que luego este sincronice el contenido al resto de los nodos. Un conjunto de nodos que colaboran con el despliegue y mantenimiento de un sitio web sólo podrán actualizarse si el nodo central está activo, lo que resulta en un único punto de falla. Por otro lado, utilizar un GitHub Action nos ata necesariamente a GitHub, lo cuál supone otra limitación para quienes deseen optar por otra alternativa para su repositorio Git.

\subsubsection{Distributed Wikipedia Mirror}

Una iniciativa destacada en este ámbito es el proyecto Distributed Wikipedia Mirror \cite{distributed-wikipedia-mirror}, que replica una versión estática de Wikipedia dentro de la red IPFS. Su objetivo principal es garantizar el acceso inalterable y resistente a la censura del contenido enciclopédico. Sin embargo, esta solución funciona únicamente en modo \textit{read-only} y se basa en \textit{snapshots} generados manualmente, lo que limita su dinamismo y capacidad de actualización en tiempo real. A pesar de estas limitaciones, demuestra la viabilidad de alojar grandes volúmenes de información en IPFS y representa un caso de uso muy cercano al repositorio de conocimiento que buscamos construir.