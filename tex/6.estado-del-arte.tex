\section{Estado del Arte}
En esta sección describiremos en qué se diferencian las aplicaciones descentralizadas de aquellas centralizadas, cuáles son las ventajas (y desventajas) del modelo de aplicación distribuido, y qué tecnologías existen actualmente para asistir en la creación de dichas aplicaciones.

\subsection{Introducción a arquitecturas de red}
La comunicación entre distintas computadoras requiere una coordinación efectiva entre todas las partes involucradas, el uso de protocolos que estandaricen la forma en que se transmite la información, y una infraestructura que permita enviar cada bit desde el origen hasta su destino. Para ofrecer servicios a través de Internet, es necesario diseñar una red bien estructurada que cumpla con estos requisitos. En este contexto, existen dos arquitecturas principales que permiten alcanzar dicho objetivo.

\subsubsection*{Cliente-Servidor}

El modelo \textit{Cliente-Servidor} es ampliamente utilizado en la mayoría de las aplicaciones disponibles en Internet. Consiste en un nodo central, el \textbf{servidor}, encargado de gestionar la interacción tanto entre los usuarios como entre cada usuario y el propio servidor. En este esquema, los demás nodos actúan como \textbf{clientes}, solicitando servicios o recursos que el servidor proporciona.

Este modelo se clasifica como una arquitectura centralizada, ya que la subred depende directamente del servidor. En caso de que este nodo central falle, los clientes pierden la capacidad de comunicarse entre sí o acceder a los servicios, lo que representa un punto único de fallo.

Entre los servicios más comunes que adoptan esta arquitectura se encuentran la World Wide Web (HTTP/HTTPS), el correo electrónico (SMTP, IMAP) y el sistema de DNS, entre otros.

\subsubsection*{Peer-to-Peer}
El modelo \textbf{peer-to-peer(P2P)} consiste en una red \textbf{descentralizada} compuesta de diferentes nodos capaces de comunicarse sin necesidad de un nodo central, por lo que se puede considerar que cada nodo cumple la función tanto de servidor como de cliente.

\paragraph{BitTorrent} El servicio más utilizado que implementa este modelo es la red de BitTorrent \cite{bittorrent}, que implementa el protocolo del mismo nombre para compartir archivos entre pares. Esta red logra que el mismo nodo que descarga un contenido de la red sea a la vez el servidor para otro nodo que quiera acceder a ese contenido. 

\subsection{Diferencias y ventajas de cada arquitectura}
Ambos modelos tienen ventajas y desventajas, y por lo tanto distintos casos de uso. El modelo cliente-servidor actualmente es la arquitectura mas utilizada.

\paragraph{Resiliencia}

En el modelo cliente-servidor, la disponibilidad de la red depende críticamente del servidor central. Si este falla o queda fuera de servicio, los clientes no pueden acceder a los recursos, lo que puede interrumpir por completo el funcionamiento del sistema. Para mitigar esta vulnerabilidad, se han implementado soluciones como la replicación de servidores en distintas ubicaciones geográficas, el balanceo de carga \cite{bourke2001server} y el uso de fuentes de energía alternativas, todo con el fin de mejorar la tolerancia a fallos y garantizar una mayor disponibilidad.

En contraste, una red P2P se basa en una arquitectura descentralizada en la que los nodos actúan simultáneamente como clientes y servidores. Esta estructura distribuye la responsabilidad entre múltiples participantes, lo que permite que la red siga operando incluso si varios nodos se desconectan. Cuando los pares están lo suficientemente dispersos geográficamente y hay una cantidad adecuada de ellos, el sistema puede mantener su funcionalidad frente a fallos locales, cortes de energía o incluso desastres naturales. Esta resiliencia inherente hace que el modelo P2P sea especialmente atractivo para servicios que requieren alta disponibilidad o continuidad operativa en condiciones adversas.

No obstante, la robustez de una red P2P depende del nivel de redundancia de los datos distribuidos. Si la red cuenta con pocos nodos o si los datos no están replicados entre varios pares, la desconexión de un nodo puede provocar la pérdida temporal de parte del contenido. En estos casos, aunque la red permanezca activa, su funcionalidad puede verse comprometida. Por tanto, garantizar la resiliencia en un entorno P2P también implica diseñar mecanismos eficientes de replicación y distribución de la información.

\paragraph{Escalabilidad}

Una de las principales ventajas de las redes peer-to-peer (P2P) es su escalabilidad. A medida que se suman más nodos a la red, también aumentan los recursos disponibles —como capacidad de procesamiento, almacenamiento y ancho de banda— lo que permite distribuir la carga de forma más eficiente. En una red P2P bien diseñada, cada nuevo participante no solo consume recursos, sino que también contribuye al sistema, favoreciendo un crecimiento orgánico y sostenible.

En cambio, en el modelo cliente-servidor, escalar implica aumentar la capacidad del servidor o incorporar servidores adicionales para atender la creciente demanda. Esto conlleva costos significativos en términos de infraestructura, mantenimiento y administración. En aplicaciones de gran escala, como redes sociales o servicios de streaming, es común la implementación de clústeres de servidores y redes de distribución de contenido (CDN) para evitar cuellos de botella y garantizar el rendimiento, lo cual aumenta la complejidad técnica y económica del sistema.

\paragraph{Control del contenido}

En una arquitectura cliente-servidor, el servidor central debe gestionar múltiples conexiones simultáneas, lo cual requiere una infraestructura robusta que la mayoría de los usuarios no está en condiciones de mantener. Por esta razón, muchas aplicaciones recurren al alojamiento en plataformas de computación en la nube, como AWS, Azure o Google Cloud. Si bien estos servicios ofrecen alta disponibilidad y escalabilidad, también centralizan el control del contenido. Esto implica que las plataformas de hosting tienen la capacidad de modificar, censurar o eliminar aplicaciones y servicios, ya sea por decisión propia, por presión de gobiernos, o en cumplimiento de políticas internas.

En contraste, una red peer-to-peer (P2P) distribuye el contenido entre los propios usuarios, quienes actúan como anfitriones del sistema. Esta descentralización hace que la moderación de contenido sea mucho más difícil, ya que no existe un único punto de control. Esta característica resulta valiosa en contextos donde el acceso a la información está restringido por censura gubernamental o limitaciones regulatorias. Sin embargo, también plantea desafíos éticos y legales, ya que dificulta el control sobre la difusión de contenidos ilícitos o perjudiciales. Así, el modelo P2P ofrece mayor libertad, pero también exige nuevas formas de regulación y responsabilidad colectiva.

\paragraph{Seguridad}

La seguridad en aplicaciones basadas en el modelo cliente-servidor ha sido ampliamente estudiada debido a su larga trayectoria y adopción masiva. La centralización permite al administrador del sistema aplicar políticas de seguridad de forma coherente, como el bloqueo de conexiones sospechosas, la autenticación de usuarios y la eliminación de contenido malicioso, todo sin requerir intervención directa del usuario final.

En cambio, las redes P2P presentan desafíos distintos. Al no existir un punto de control central, la responsabilidad de establecer conexiones seguras recae en cada nodo participante. La ausencia de una autoridad central puede dificultar la detección y mitigación de comportamientos maliciosos dentro de la red.

Sin embargo, independientemente del modelo arquitectónico adoptado, la seguridad general de una aplicación dependerá en gran medida de su propio diseño: el uso adecuado de cifrado, autenticación, y la gestión de vulnerabilidades son factores determinantes para garantizar la protección de los datos y de los usuarios.

\paragraph{Persistencia}

En redes descentralizadas, la persistencia depende del comportamiento de los nodos y de las características específicas de la aplicación. En sistemas como BitTorrent, cada nodo que descarga un archivo puede continuar compartiéndolo con otros participantes, lo que genera una forma de redundancia dinámica: a medida que más usuarios descargan un archivo, aumentan las copias disponibles en la red. Sin embargo, si un archivo no es ampliamente compartido, puede volverse inaccesible cuando los pocos nodos que lo contienen se desconectan. En este sentido, la persistencia en redes peer-to-peer no está garantizada por diseño, sino que depende del nivel de replicación voluntaria entre los pares.

\paragraph{Latencia}
Dada una conexión a Internet promedio, las velocidades manejadas por las aplicaciones cliente-servidor suelen ser aceptables. Sin embargo, en zonas en donde la conexión es escasa, o en casos en donde el servidor está lejos del cliente, la velocidad de transferencia de la aplicación puede verse afectada. Además, no es infrecuente encontrar cortes en videollamadas, videojuegos, y demás aplicaciones de tiempo real que siguen esta arquitectura. Como en la mayoría de defectos del modelo cliente-servidor, se puede solucionar agregando múltiples instancias del servidor. Por ejemplo, es común almacenar  películas, videos y demás contenido de aplicaciones de streaming en distintos servidores de CDN (Content Delivery Network). Estas redes minimizan la distancia entre el usuario y el servidor, agilizando así la transferencia del contenido.

A pesar de los avances en la optimización del modelo cliente-servidor, las redes descentralizadas, cuando son eficientes y están bien pobladas, suelen ofrecer incluso mejores resultados. Esto se debe a que la fuente de un contenido puede estar presente en múltiples nodos, lo que aumenta la probabilidad de que un nodo cercano tenga el contenido solicitado. La velocidad de transferencia que puede proporcionar un vecino con el contenido que requerimos generalmente superará la ofrecida por un servidor.

\paragraph{Costos}

Una de las ventajas del modelo peer-to-peer (P2P) es su bajo costo operativo. Dado que los propios usuarios de la red aportan recursos como almacenamiento, procesamiento y ancho de banda, no es necesario mantener una infraestructura centralizada para alojar la aplicación. Esto reduce considerablemente los gastos asociados a la implementación y mantenimiento del sistema.

En contraste, el modelo cliente-servidor requiere disponer de un servidor dedicado o contratar servicios de alojamiento web, cuyos costos suelen incrementarse a medida que la aplicación escala y atrae más usuarios. Estos gastos incluyen no solo el hardware o el servicio de hosting, sino también aspectos como soporte técnico, ancho de banda adicional y medidas de seguridad. Por ello, las arquitecturas descentralizadas pueden representar una alternativa económicamente viable, especialmente en contextos donde los recursos financieros son limitados o se busca una solución escalable con bajo mantenimiento central.

\subsection{Ambientes y herramientas}
Existen varios ecosistemas que apuntan a proveer un marco con el cuál desarrollar una aplicación descentralizada. A su vez, cada uno de ellos cuenta con herramientas especializadas para los diferentes tipos de aplicaciones.

\subsubsection{IPFS}

\textbf{IPFS} (InterPlanetary File System) es un conjunto modular de protocolos diseñado para la organización y transferencia de datos en una red peer-to-peer, basado en el principio de \textit{content addressing}, es decir, la recuperación de archivos en función de su contenido y no de su ubicación o identificador arbitrario \cite{ipfs}. Su principal propósito es facilitar la publicación de datos como archivos, directorios y sitios web de forma descentralizada.

Este enfoque representa una alternativa al modelo tradicional de la web, que se basa en el direccionamiento por ubicación (\textit{location-based addressing}), como ocurre con HTTP. Dicho modelo impone limitaciones estructurales que son contrarias a los principios de descentralización, resiliencia y autonomía que caracterizan a las aplicaciones comunitarias y distribuidas.

IPFS, en cambio, propone una red abierta, participativa y sin control centralizado, donde cualquier usuario puede contribuir y operar como nodo. Esta descentralización no solo elimina la dependencia de servicios de terceros para el despliegue de aplicaciones —lo cual puede ser costoso—, sino que también permite a los propios usuarios colaborar activamente con recursos de sus dispositivos para sostener el funcionamiento de la red.

Además, gracias al direccionamiento por contenido, cada archivo en IPFS cuenta con un identificador único (CID), lo que permite un acceso persistente y distribuido desde múltiples ubicaciones. Esta característica mejora la disponibilidad del contenido y fortalece la resistencia frente a intentos de censura o interrupciones del servicio.

En este contexto, IPFS constituye una base tecnológica especialmente adecuada para el desarrollo de aplicaciones descentralizadas. A continuación, se presentan algunas de las herramientas más relevantes que conforman su ecosistema.

\paragraph{libp2p} Colección de protocolos y utilidades para facilitar la implementación de una red peer-to-peer \cite{libp2p}. Entre sus herramientas, se encuentran diferentes mecanismos de seguridad, de transporte, y para descubrimiento de pares. Se creó con IPFS en mente, pero luego se expandió a un conjunto de protocolos independiente, el cual es utilizado por Ethereum actualmente. Los protocolos de interés para este proyecto son:
\subparagraph{Protocolos de transporte} Son los encargados de la comunicación entre nodos, de manera similar a la capa de transporte presente en toda red convencional. Se basan en tipos de transporte ya existentes, adaptados al uso peer-to-peer. Los protocolos principales son TCP, WebSockets y WebRTCDirect.
\subparagraph{Protocolos de descubrimiento de peers} Para encontrar un contenido en IPFS, se necesita saber la dirección del nodo que tiene dicho contenido. El principal protocolo para lograr esto se denomina Distributed Hash Table (DHT) \cite{dht} \cite{kadmelia}. Es un registro clave-valor distribuido en todos los nodos que soporten este protocolo, que contiene la información necesaria para encontrar el contenido deseado. Cada nodo tiene una parte de esta tabla, y deberá preguntar a otros nodos hasta conseguir la dirección del nodo asociada a la dirección del contenido buscado.

\paragraph{Kubo} La implementación principal de IPFS es Kubo \cite{kubo}, una solución hecha en Go. Tiene su propio comando en la terminal, llamado \texttt{ipfs}, y también es utilizado en los demás front-ends de IPFS como IPFS desktop, la aplicación de escritorio de IPFS. Es la más madura y desarrollada de las dos implementaciones de IPFS, y cuenta con más funcionalidades.

\paragraph{IPFS Cluster} Herramienta para orquestar distintos nodos de IPFS, con el objetivo de mantener disponible un contenido en la red de IPFS, aumentando su disponibilidad. Por defecto, cualquier nodo puede modificar la lista de archivos que mantiene el \textit{cluster}.
\subparagraph{Clusters colaborativos} Son clusters que permiten que usuarios puedan colaborar con su nodo y aumentar la disponibilidad del contenido, sin tener permiso para modificar los archivos que se están manteniendo \cite{collaborative-clusters}. Esto es ideal para una aplicación comunitaria debido a esta medida de seguridad que permite al cluster ser apoyado por cualquier usuario de una comunidad.

\paragraph{OrbitDB}
OrbitDB es una base de datos descentralizada y peer-to-peer construida sobre \textbf{IPFS} para el almacenamiento de datos, y utiliza \textbf{libp2p} para la sincronización entre nodos \cite{orbitdb}. Su modelo es de consistencia eventual, lo que significa que los cambios realizados en una base de datos no se reflejan de manera inmediata en todos los nodos de la red, sino que se propagan de forma progresiva con el tiempo.
OrbitDB ha sido desarrollada principalmente dentro del ecosistema de \textit{JavaScript}, lo que facilita su integración en aplicaciones web. Esta característica permite ejecutar nodos directamente en el navegador.

\paragraph{Helia} Para crear una instancia de un nodo de OrbitDB se debe pasar como parámetro una instancia de Helia. Helia \cite{helia} es la implementación de IPFS para Javascript, y, como OrbitDB, también puede ejecutarse en un navegador. A diferencia de Kubo, Helia tiene un enfoque mucho más abierto, permitiendo la configuración del nodo libp2p utilizado internamente de manera abierta. Esto implica un trade-off claro: más configuración permite un nodo de IPFS que se puede adaptar a diferentes escenarios, pero también implica una mayor complejidad a la hora de lograr un funcionamiento correcto del nodo.

\subsubsection{Blockchain}
Tecnología basada en una cadena de bloques de operaciones descentralizada y pública.  Esta tecnología genera una base de datos compartida a la que tienen acceso sus participantes, los cuáles pueden rastrear cada transacción que hayan realizado.\parencite{blockchain}

% \footnote{https://www.iebschool.com/blog/blockchain-cadena-bloques-revoluciona-sector-financiero-finanzas/}

\subsubsection{Alternativas}
\paragraph{Hyphanet} \cite{hyphanet-white-paper} \cite{hyphanet} es una plataforma peer-to-peer para publicar y comunicar, resistente a la censura y respetuosa de la privacidad. Originalmente conocido como Freenet y creado como un trabajo profesional de fin de carrera por Ian Clarke, Hyphanet es una plataforma de software libre que permite compartir archivos, navegar y publicar sitios de forma anónima. Es descentralizado para hacerlo menos vulnerable a ataques, y de ser usado sólo con personas de confianza lo hace difícil de detectar para agentes externos.

\paragraph{Freenet} \cite{freenet} es una red peer-to-peer para servicios descentralizados, sin censura, en donde los usuarios tengan el control del contenido. Es una plataforma que transforma las computadoras de sus usuarios en plataformas distribuidas y resilientes en la que se pueden construir aplicaciones descentralizadas. Cada peer contribuye a un colectivo tolerante a fallas, asegurando que los servicios robustos que estén siempre disponibles.

Creado por Ian Clarke, el mismo creador de \textit{Hyphanet} \cite{hyphanet}, es una plataforma nueva que busca ser una computadora descentralizada en reemplazo de servidores centralizados. Está hecha en Rust y utiliza WebAssembly para ejecutar las aplicaciones.


\subsection{Soluciones existentes}

\subsubsection{IPFS Deploy Action}
Para desplegar un sitio web en IPFS, se puede utilizar un \textit{GitHub Action} hecho por IPFS y lanzado en Febrero de 2025. Dicha herramienta es un script que se ejecuta con cada commit en un repositorio de GitHub, y permite compilar el sitio web, y luego alojarlo en IPFS utilizando un servicio de \textit{pinning}, Filecoin, o bien un clúster de IPFS. Estas opciones se verán en detalle cuando se abarque la arquitectura de despliegue implementada.

Sin embargo cuenta con una serie de desventajas al utilizar clústeres. Por un lado, utilizando la opción de clúster sólo puede instruir a un único nodo para que luego este sincronice el contenido al resto de los nodos. Un conjunto de nodos que colaboran con el despliegue y mantenimiento de un sitio web sólo podrán actualizarse si el nodo central está activo, lo que resulta en un único punto de falla. Por otro lado, utilizar un \textit{GitHub Action} nos ata necesariamente a \textit{GitHub}, lo cuál supone otra limitación para quienes deseen optar por otra alternativa para su repositorio Git.

\subsubsection{Distributed Wikipedia Mirror}

Una iniciativa destacada en este ámbito es el proyecto Distributed Wikipedia Mirror \cite{distributed-wikipedia-mirror}, que replica una versión estática de Wikipedia dentro de la red IPFS. Su objetivo principal es garantizar el acceso inalterable y resistente a la censura del contenido enciclopédico. Sin embargo, esta solución funciona únicamente en modo read-only y se basa en snapshots generados manualmente, lo que limita su dinamismo y capacidad de actualización en tiempo real. A pesar de estas limitaciones, demuestra la viabilidad de alojar grandes volúmenes de información en IPFS y representa un caso de uso muy cercano al repositorio de conocimiento que buscamos construir.